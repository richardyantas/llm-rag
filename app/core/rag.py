# from googletrans import Translator
import cohere
import chromadb
import os
import emoji
from langdetect import detect
from dotenv import load_dotenv
from pathlib import Path
from chromadb.config import Settings
from langchain.prompts import PromptTemplate

curr_dir = Path(__file__).parent
env_path = curr_dir.parent.parent / '.env'
vectordatabase_path = curr_dir.parent / 'datavector'
load_dotenv(dotenv_path=env_path, override=True)
cohere_api_key = os.getenv("COHERE_API_KEY")
collection_name = os.getenv("CHROMA_COLLECTION_NAME")
client = chromadb.Client(Settings(is_persistent=True, persist_directory=str(vectordatabase_path)))
collection = client.get_collection(collection_name)
co = cohere.Client(cohere_api_key)

def query_embeddings(question):  # retrieval context (chunk most similar to query embedded)
    question_embedding = co.embed(texts=[question], model="large", truncate="RIGHT").embeddings[0]    
    results = collection.query(query_embeddings=[question_embedding], n_results=1) # Buscar el chunk mÃ¡s similar en ChromaDB
    return results["documents"][0]  # Retorna el chunk mÃ¡s relevante

def translate_text(text, target_language):
    # translator = Translator()
    # translated = translator.translate(text, dest=target_language)
    # return translated.text
    return text

def create_prompt_translated(user_question, context):
    # Detectar el idioma de la pregunta
    language = detect(user_question)

    prompt = f"""
      Contexto: {context}
      Pregunta: {user_question}
      Instruccion:
      - Responder en solo una oraciÃ³n.
      - Siempre responder en el idioma {language}.
      - Responder en tercera persona.
      - Agrega algunos emojis
      """
    
    # prompt = f"""
    # La respuesta a la siguiente pregunta debe ser breve, en una sola oraciÃ³n, en idioma {language} en tercera persona, y agregar emojis relacionados con el contenido:
    # Contexto: {context}
    # Pregunta: {user_question}
    # Respuesta:
    # """
    #  Agregar emojis dentro del contenido de la respuesta.
    # prompt_lang = translate_text(prompt, language)
    # return prompt_lang
    return prompt


predefined_answers = {
    "Â¿CuÃ¡l es la capital de Francia?": "La capital de Francia es ParÃ­s. ğŸ—¼ğŸ‡«ğŸ‡·",
    "What is the capital of France?": "The capital of France is Paris. ğŸ—¼ğŸ‡«ğŸ‡·",
    "Qual Ã© a capital da FranÃ§a?": "A capital da FranÃ§a Ã© Paris. ğŸ—¼ğŸ‡«ğŸ‡·",
    "Â¿quien es zara?": "Zara ğŸš€ es un explorador intrÃ©pido y valiente ğŸƒâ™‚ï¸ğŸ¹, que viaja en busca de la paz para su galaxy ğŸŒŒ, en la lejana galaxia de"
}

def add_emojis(text):
    return emoji.emojize(text, use_aliases=True)

def process_question(question, chain):    
    if question in predefined_answers:
        return predefined_answers[question]    
    # Generar una respuesta en funciÃ³n del idioma detectado
    response_text = chain.run(question)
    response_with_emojis = add_emojis(response_text)
    return response_with_emojis

def generate_response(question, context):
    # Generar una respuesta utilizando Cohere
    prompt = create_prompt_translated(question, context)
    # work here add langchain to add emojis
    print(prompt)
    #model="command-xlarge"
    response = co.generate(prompt=prompt,
                           max_tokens=50,  # Ajusta el nÃºmero de tokens segÃºn sea necesario
                           temperature=0.5 # Ajusta la temperatura para variar la creatividad
                           ).generations[0].text
    return response


def generate_answer(question):
    # question = "Qual Ã¨ il nome del fiore magico?"
    relevant_chunk = query_embeddings(question)    
    response = generate_response(question, relevant_chunk)
    print(response)
    # print(detect(response)) # error
    return response

# question = "Qual Ã¨ il nome del fiore magico?"
# relevant_chunk = query_embeddings(question)    
# response = generate_response(question, relevant_chunk)
# print(response)
# # print(detect(response))